{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tts_models/multilingual/multi-dataset/xtts_v2', 'tts_models/multilingual/multi-dataset/xtts_v1.1', 'tts_models/multilingual/multi-dataset/your_tts', 'tts_models/multilingual/multi-dataset/bark', 'tts_models/bg/cv/vits', 'tts_models/cs/cv/vits', 'tts_models/da/cv/vits', 'tts_models/et/cv/vits', 'tts_models/ga/cv/vits', 'tts_models/en/ek1/tacotron2', 'tts_models/en/ljspeech/tacotron2-DDC', 'tts_models/en/ljspeech/tacotron2-DDC_ph', 'tts_models/en/ljspeech/glow-tts', 'tts_models/en/ljspeech/speedy-speech', 'tts_models/en/ljspeech/tacotron2-DCA', 'tts_models/en/ljspeech/vits', 'tts_models/en/ljspeech/vits--neon', 'tts_models/en/ljspeech/fast_pitch', 'tts_models/en/ljspeech/overflow', 'tts_models/en/ljspeech/neural_hmm', 'tts_models/en/vctk/vits', 'tts_models/en/vctk/fast_pitch', 'tts_models/en/sam/tacotron-DDC', 'tts_models/en/blizzard2013/capacitron-t2-c50', 'tts_models/en/blizzard2013/capacitron-t2-c150_v2', 'tts_models/en/multi-dataset/tortoise-v2', 'tts_models/en/jenny/jenny', 'tts_models/es/mai/tacotron2-DDC', 'tts_models/es/css10/vits', 'tts_models/fr/mai/tacotron2-DDC', 'tts_models/fr/css10/vits', 'tts_models/uk/mai/glow-tts', 'tts_models/uk/mai/vits', 'tts_models/zh-CN/baker/tacotron2-DDC-GST', 'tts_models/nl/mai/tacotron2-DDC', 'tts_models/nl/css10/vits', 'tts_models/de/thorsten/tacotron2-DCA', 'tts_models/de/thorsten/vits', 'tts_models/de/thorsten/tacotron2-DDC', 'tts_models/de/css10/vits-neon', 'tts_models/ja/kokoro/tacotron2-DDC', 'tts_models/tr/common-voice/glow-tts', 'tts_models/it/mai_female/glow-tts', 'tts_models/it/mai_female/vits', 'tts_models/it/mai_male/glow-tts', 'tts_models/it/mai_male/vits', 'tts_models/ewe/openbible/vits', 'tts_models/hau/openbible/vits', 'tts_models/lin/openbible/vits', 'tts_models/tw_akuapem/openbible/vits', 'tts_models/tw_asante/openbible/vits', 'tts_models/yor/openbible/vits', 'tts_models/hu/css10/vits', 'tts_models/el/cv/vits', 'tts_models/fi/css10/vits', 'tts_models/hr/cv/vits', 'tts_models/lt/cv/vits', 'tts_models/lv/cv/vits', 'tts_models/mt/cv/vits', 'tts_models/pl/mai_female/vits', 'tts_models/pt/cv/vits', 'tts_models/ro/cv/vits', 'tts_models/sk/cv/vits', 'tts_models/sl/cv/vits', 'tts_models/sv/cv/vits', 'tts_models/ca/custom/vits', 'tts_models/fa/custom/glow-tts', 'tts_models/bn/custom/vits-male', 'tts_models/bn/custom/vits-female', 'tts_models/be/common-voice/glow-tts', 'vocoder_models/universal/libri-tts/wavegrad', 'vocoder_models/universal/libri-tts/fullband-melgan', 'vocoder_models/en/ek1/wavegrad', 'vocoder_models/en/ljspeech/multiband-melgan', 'vocoder_models/en/ljspeech/hifigan_v2', 'vocoder_models/en/ljspeech/univnet', 'vocoder_models/en/blizzard2013/hifigan_v2', 'vocoder_models/en/vctk/hifigan_v2', 'vocoder_models/en/sam/hifigan_v2', 'vocoder_models/nl/mai/parallel-wavegan', 'vocoder_models/de/thorsten/wavegrad', 'vocoder_models/de/thorsten/fullband-melgan', 'vocoder_models/de/thorsten/hifigan_v1', 'vocoder_models/ja/kokoro/hifigan_v1', 'vocoder_models/uk/mai/multiband-melgan', 'vocoder_models/tr/common-voice/hifigan', 'vocoder_models/be/common-voice/hifigan', 'voice_conversion_models/multilingual/vctk/freevc24']\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": " ‚ùó Language vie is not supported. Supported languages are ['en', 'es', 'fr', 'de', 'it', 'pt', 'pl', 'tr', 'ru', 'nl', 'cs', 'ar', 'zh-cn', 'hu', 'ko', 'ja', 'hi']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 30\u001b[0m\n\u001b[0;32m     13\u001b[0m script \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124m  Hey, have you heard about this new text-to-audio model called \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBark\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124m  Apparently, it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms the most realistic and natural-sounding text-to-audio model\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124m  be a game-changer in the world of text-to-audio technology.\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Run TTS\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# ‚ùó Since this model is multi-lingual voice cloning model, we must set the target speaker_wav and language\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Text to speech list of amplitude values as output\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# wav = tts.tts(text=\"Hello world!\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\")\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Text to speech to a file\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[43mtts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeaker_wav\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mref-a-cut.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvie\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput-test.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\TTS\\api.py:334\u001b[0m, in \u001b[0;36mTTS.tts_to_file\u001b[1;34m(self, text, speaker, language, speaker_wav, emotion, speed, pipe_out, file_path, split_sentences, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert text to speech.\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;124;03m        Additional arguments for the model.\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_arguments(speaker\u001b[38;5;241m=\u001b[39mspeaker, language\u001b[38;5;241m=\u001b[39mlanguage, speaker_wav\u001b[38;5;241m=\u001b[39mspeaker_wav, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 334\u001b[0m wav \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeaker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeaker_wav\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_wav\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_sentences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_sentences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynthesizer\u001b[38;5;241m.\u001b[39msave_wav(wav\u001b[38;5;241m=\u001b[39mwav, path\u001b[38;5;241m=\u001b[39mfile_path, pipe_out\u001b[38;5;241m=\u001b[39mpipe_out)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file_path\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\TTS\\api.py:276\u001b[0m, in \u001b[0;36mTTS.tts\u001b[1;34m(self, text, speaker, language, speaker_wav, emotion, speed, split_sentences, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert text to speech.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m        Additional arguments for the model.\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_arguments(\n\u001b[0;32m    274\u001b[0m     speaker\u001b[38;5;241m=\u001b[39mspeaker, language\u001b[38;5;241m=\u001b[39mlanguage, speaker_wav\u001b[38;5;241m=\u001b[39mspeaker_wav, emotion\u001b[38;5;241m=\u001b[39memotion, speed\u001b[38;5;241m=\u001b[39mspeed, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    275\u001b[0m )\n\u001b[1;32m--> 276\u001b[0m wav \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthesizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeaker_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlanguage_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeaker_wav\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_wav\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreference_wav\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstyle_wav\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstyle_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreference_speaker_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_sentences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_sentences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wav\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\TTS\\utils\\synthesizer.py:389\u001b[0m, in \u001b[0;36mSynthesizer.tts\u001b[1;34m(self, text, speaker_name, language_name, speaker_wav, style_wav, style_text, reference_wav, reference_speaker_name, split_sentences, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sen \u001b[38;5;129;01min\u001b[39;00m sens:\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msynthesize\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 389\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthesize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspeaker_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvoice_dirs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvoice_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[43md_vector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspeaker_wav\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_wav\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguage_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    400\u001b[0m         \u001b[38;5;66;03m# synthesize voice\u001b[39;00m\n\u001b[0;32m    401\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m synthesis(\n\u001b[0;32m    402\u001b[0m             model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_model,\n\u001b[0;32m    403\u001b[0m             text\u001b[38;5;241m=\u001b[39msen,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    411\u001b[0m             language_id\u001b[38;5;241m=\u001b[39mlanguage_id,\n\u001b[0;32m    412\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\TTS\\tts\\models\\xtts.py:402\u001b[0m, in \u001b[0;36mXtts.synthesize\u001b[1;34m(self, text, config, speaker_wav, language, speaker_id, **kwargs)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msynthesize\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, config, speaker_wav, language, speaker_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    386\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Synthesize speech with the given input text.\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    399\u001b[0m \n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m--> 402\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzh-cn\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m language \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzh\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m language \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlanguages\n\u001b[0;32m    403\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ‚ùó Language \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not supported. Supported languages are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlanguages\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;66;03m# Use generally found best tuning knobs for generation.\u001b[39;00m\n\u001b[0;32m    405\u001b[0m     settings \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mtemperature,\n\u001b[0;32m    407\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mlength_penalty,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mtop_p,\n\u001b[0;32m    411\u001b[0m     }\n",
      "\u001b[1;31mAssertionError\u001b[0m:  ‚ùó Language vie is not supported. Supported languages are ['en', 'es', 'fr', 'de', 'it', 'pt', 'pl', 'tr', 'ru', 'nl', 'cs', 'ar', 'zh-cn', 'hu', 'ko', 'ja', 'hi']"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from TTS.api import TTS\n",
    "\n",
    "# Get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# List available üê∏TTS models\n",
    "print(TTS().list_models())\n",
    "\n",
    "# Init TTS\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "\n",
    "script = \"\"\"\n",
    "  Hey, have you heard about this new text-to-audio model called \"Bark\"?\n",
    "  Apparently, it's the most realistic and natural-sounding text-to-audio model\n",
    "  out there right now. People are saying it sounds just like a real person speaking.\n",
    "  I think it uses advanced machine learning algorithms to analyze and understand the\n",
    "  nuances of human speech, and then replicates those nuances in its own speech output.\n",
    "  It's pretty impressive, and I bet it could be used for things like audiobooks or podcasts.\n",
    "  In fact, I heard that some publishers are already starting to use Bark to create audiobooks.\n",
    "  It would be like having your own personal voiceover artist. I really think Bark is going to\n",
    "  be a game-changer in the world of text-to-audio technology.\n",
    "\"\"\".replace(\"\\n\", \" \").strip()\n",
    "\n",
    "# Run TTS\n",
    "# ‚ùó Since this model is multi-lingual voice cloning model, we must set the target speaker_wav and language\n",
    "# Text to speech list of amplitude values as output\n",
    "# wav = tts.tts(text=\"Hello world!\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\")\n",
    "# Text to speech to a file\n",
    "tts.tts_to_file(text=script, speaker_wav=\"ref-a-cut.wav\", language=\"vie\", file_path=\"output-test.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
